{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab4f5b11-aa13-400d-9b0b-1db2952efbb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !source my_env/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85d48c58-45cb-4f53-9da9-dd543b1c293b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.14\n"
     ]
    }
   ],
   "source": [
    "! python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb2090d9-47fc-437d-afce-9a2eef919967",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-discoveryengine in /opt/conda/lib/python3.10/site-packages (0.13.4)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (2.24.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-discoveryengine) (2.32.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-discoveryengine) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-discoveryengine) (3.20.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (1.63.2)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (1.51.3)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (1.48.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-discoveryengine) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-discoveryengine) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-discoveryengine) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-discoveryengine) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "# Install the packages\n",
    "! pip3 install --upgrade --quiet google-cloud-aiplatform\n",
    "! pip install google-cloud-discoveryengine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "412468e1-2fb9-40c1-a55e-0bdab6fdc8d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup project ID and location\n",
    "PROJECT_ID = \"cacafly-ml-specialization\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0ac89fd-0f40-4c78-8743-fb3cf8511103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.language_models import CodeGenerationModel\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd81ef20-249f-4692-a21c-9761021b2532",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import os\n",
    "import vertexai\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from google.cloud import discoveryengine\n",
    "from google.protobuf.json_format import MessageToDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88b2132-fd0b-4270-833e-bee6c69c86d8",
   "metadata": {},
   "source": [
    "### Set Up Vertex AI Search Engine and Get Search Engine Id\n",
    "\n",
    "\n",
    "Âú® Agent Builder ‰∏äÂª∫Á´ã‰∏ÄÂÄã Data Store, index websites ‰∏¶‰∏îË§áË£Ω engine_id\n",
    "\n",
    "Á∂≤Á´ô‰ΩøÁî®ÁØÑ‰æãÊèê‰æõÁöÑÔºösupport.google.com/google-ads/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2772b29b-1349-4fd6-8e92-f18747f63e9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_engine_id = \"demo3_1733212957986\"\n",
    "serving_config_id = \"default_config\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd549f5-3295-4f60-89e5-7ef7c3389023",
   "metadata": {},
   "source": [
    "### Import dataset and related package (NEW)\n",
    "\n",
    "data source: https://www.cs.cornell.edu/people/pabo/movie-review-data/\n",
    "\n",
    "ref code source: https://www.kaggle.com/code/esraaaabdelrazek/moviereviewclassification/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d74aa023-3312-4289-b98e-b07615c3a6b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import tarfile\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.datasets import load_files\n",
    "import nltk \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e78b2e25-b2e2-459e-b695-1d622c8d57ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movie_data = load_files('txt_sentoken/')\n",
    "X , y = movie_data.data , movie_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72950c51-25a9-4afd-9a9e-af26526d1078",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"arnold schwarzenegger has been an icon for action enthusiasts , since the late 80's , but lately his films have been very sloppy and the one-liners are getting worse . \\nit's hard seeing arnold as mr . freeze in batman and robin , especially when he says tons of ice jokes , but hey he got 15 million , what's it matter to him ? \\nonce again arnold has signed to do another expensive blockbuster , that can't compare with the likes of the terminator series , true lies and even eraser . \\nin this so called dark thriller , the devil ( gabriel byrne ) has come upon earth , to impregnate a woman ( robin tunney ) which happens every 1000 years , and basically destroy the world , but apparently god has chosen one man , and that one man is jericho cane ( arnold himself ) . \\nwith the help of a trusty sidekick ( kevin pollack ) , they will stop at nothing to let the devil take over the world ! \\nparts of this are actually so absurd , that they would fit right in with dogma . \\nyes , the film is that weak , but it's better than the other blockbuster right now ( sleepy hollow ) , but it makes the world is not enough look like a 4 star film . \\nanyway , this definitely doesn't seem like an arnold movie . \\nit just wasn't the type of film you can see him doing . \\nsure he gave us a few chuckles with his well known one-liners , but he seemed confused as to where his character and the film was going . \\nit's understandable , especially when the ending had to be changed according to some sources . \\naside form that , he still walked through it , much like he has in the past few films . \\ni'm sorry to say this arnold but maybe these are the end of your action days . \\nspeaking of action , where was it in this film ? \\nthere was hardly any explosions or fights . \\nthe devil made a few places explode , but arnold wasn't kicking some devil butt . \\nthe ending was changed to make it more spiritual , which undoubtedly ruined the film . \\ni was at least hoping for a cool ending if nothing else occurred , but once again i was let down . \\ni also don't know why the film took so long and cost so much . \\nthere was really no super affects at all , unless you consider an invisible devil , who was in it for 5 minutes tops , worth the overpriced budget . \\nthe budget should have gone into a better script , where at least audiences could be somewhat entertained instead of facing boredom . \\nit's pitiful to see how scripts like these get bought and made into a movie . \\ndo they even read these things anymore ? \\nit sure doesn't seem like it . \\nthankfully gabriel's performance gave some light to this poor film . \\nwhen he walks down the street searching for robin tunney , you can't help but feel that he looked like a devil . \\nthe guy is creepy looking anyway ! \\nwhen it's all over , you're just glad it's the end of the movie . \\ndon't bother to see this , if you're expecting a solid action flick , because it's neither solid nor does it have action . \\nit's just another movie that we are suckered in to seeing , due to a strategic marketing campaign . \\nsave your money and see the world is not enough for an entertaining experience . \\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3070a659-ee85-462e-ab0e-0d909e00114b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03ec9317-5da3-4a8f-861d-15f58fee6eea",
   "metadata": {},
   "source": [
    "## split review to 2 paragraph and combine randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd513ffd-75a7-49fa-bca7-5e236344be2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "\n",
    "model = GenerativeModel(\"gemini-2.0-flash-001\")\n",
    "\n",
    "def clean_named_entities(texts):\n",
    "    responses = []\n",
    "    for text in tqdm(texts):\n",
    "        prompt = (\n",
    "            \"Please remove all names of people and works of art (like movies, books, songs) \"\n",
    "            \"from the following text, but keep the grammar and sentence structure as natural as possible.\\n\"\n",
    "            f\"Original Text:\\n{text}\\nCleaned Text:\"\n",
    "        )\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            responses.append(response.text.strip())\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            responses.append(text)  # fallback\n",
    "    return responses\n",
    "\n",
    "# def clean_named_entities(text):\n",
    "#     prompt = (\n",
    "#         \"Please remove all names of people and works of art (like movies, books, songs) \"\n",
    "#         \"from the following text, but keep the grammar and sentence structure as natural as possible.\\n\"\n",
    "#         f\"Original Text:\\n{text}\\nCleaned Text:\"\n",
    "#     )\n",
    "#     try:\n",
    "#         response = model.generate_content(prompt)\n",
    "#         return response.text.strip()\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Error in Gemini API: {e}\")\n",
    "#         return text  # fallback to original\n",
    "\n",
    "def split_review(text, min_split=5):\n",
    "    if isinstance(text, bytes):\n",
    "        text = text.decode(\"utf-8\")\n",
    "        \n",
    "    # print(text)\n",
    "    ''''''\n",
    "    # text = clean_named_entities(text)  # üßº ÁßªÈô§ËßíËâ≤ÂêçËàáÁâáÂêç\n",
    "    ''''''\n",
    "    # paragraphs = [p.strip() for p in text.strip().split('\\n') if p.strip()]\n",
    "    paragraphs = [p.strip() for p in text.strip().split('.') if p.strip()]\n",
    "    if len(paragraphs) < min_split:\n",
    "        mid = len(paragraphs) // 2\n",
    "    else:\n",
    "        total_len = sum(len(p) for p in paragraphs)\n",
    "        acc_len = 0\n",
    "        for i, p in enumerate(paragraphs):\n",
    "            acc_len += len(p)\n",
    "            if acc_len >= total_len / 2:\n",
    "                mid = i + 1\n",
    "                break\n",
    "    # print(mid)\n",
    "    # if mid == 0:\n",
    "    #     print(text)\n",
    "    #     jahaaaa\n",
    "    return \"\\n\".join(paragraphs[:mid]), \"\\n\".join(paragraphs[mid:])\n",
    "\n",
    "def split_review_random_choose_sentence(text, min_split=5, sample_ratio=0.4):\n",
    "    if isinstance(text, bytes):\n",
    "        text = text.decode(\"utf-8\")\n",
    "\n",
    "    # ÂàáÊÆµËêΩ\n",
    "    paragraphs = [p.strip() for p in text.strip().split('.') if p.strip()]\n",
    "\n",
    "    # ÂàÜÂâçÂæåÊÆµ\n",
    "    if len(paragraphs) < min_split:\n",
    "        mid = len(paragraphs) // 2\n",
    "    else:\n",
    "        total_len = sum(len(p) for p in paragraphs)\n",
    "        acc_len = 0\n",
    "        for i, p in enumerate(paragraphs):\n",
    "            acc_len += len(p)\n",
    "            if acc_len >= total_len / 2:\n",
    "                mid = i + 1\n",
    "                break\n",
    "    \n",
    "    ### minus first and last sentence\n",
    "    '''\n",
    "    start = 0\n",
    "    if mid >= 2:\n",
    "        start = 1\n",
    "    front = \"\\n\".join(paragraphs[start:mid-1])\n",
    "    back = \"\\n\".join(paragraphs[mid+1:])\n",
    "    \n",
    "    # front = paragraphs[start:mid-1]\n",
    "    # back = paragraphs[mid+1:]\n",
    "    \n",
    "    return front, back\n",
    "    '''\n",
    "\n",
    "    ### random choose 40% sentence \n",
    "    \n",
    "    # ÂàÜÂè•\n",
    "    front_sents = paragraphs[:mid]\n",
    "    back_sents = paragraphs[mid:]\n",
    "\n",
    "\n",
    "    # ÂêÑÊÆµË¶ÅÊäΩÁöÑÂè•Êï∏Ôºà‰øùÂ∫ïÊäΩ 1 Âè•Ôºâ\n",
    "    n_front = max(1, round(len(front_sents) * sample_ratio)) if front_sents else 0\n",
    "    n_back = max(1, round(len(back_sents) * sample_ratio)) if back_sents else 0\n",
    "    # print('front_sents', len(front_sents), len(back_sents))\n",
    "    \n",
    "    # Èö®Ê©üÊäΩ index ‰∏¶‰øùÊåÅÈ†ÜÂ∫è\n",
    "    front_idx = sorted(random.sample(range(len(front_sents)), n_front)) if n_front > 0 else []\n",
    "    back_idx = sorted(random.sample(range(len(back_sents)), n_back)) if n_back > 0 else []\n",
    "\n",
    "    selected_front = [front_sents[i] for i in front_idx]\n",
    "    selected_back = [back_sents[i] for i in back_idx]\n",
    "\n",
    "    # print('selected_front', len(selected_front), len(selected_back))\n",
    "    # # ‰øùÂ∫ïÂêÑÊäΩ‰∏ÄÂè•ÔºàÂ¶ÇÊûúÊúâÂè•Â≠êÁöÑË©±Ôºâ\n",
    "    ''' *** only one sentence version ***'''\n",
    "    # selected_front = [random.choice(front_sents[1:])] if len(front_sents) > 1 else []\n",
    "    # selected_back = [random.choice(back_sents)] if back_sents else []\n",
    "\n",
    "\n",
    "    return \"\\n\".join(selected_front), \"\\n\".join(selected_back)\n",
    "\n",
    "def build_finetune_data(X, y, train_path=\"train.jsonl\", valid_path=\"eval.jsonl\", sample_size_each=500):\n",
    "    pos_reviews = [r for r, label in zip(X, y) if label == 1]\n",
    "    neg_reviews = [r for r, label in zip(X, y) if label == 0]\n",
    "\n",
    "    assert len(pos_reviews) >= sample_size_each * 2, \"Not enough positive reviews\"\n",
    "    assert len(neg_reviews) >= sample_size_each * 2, \"Not enough negative reviews\"\n",
    "\n",
    "    pos_yes = random.sample(pos_reviews, sample_size_each) #[:50]\n",
    "    neg_yes = random.sample(neg_reviews, sample_size_each) #[:50]\n",
    "\n",
    "    yes_samples = []\n",
    "    \n",
    "    print('yes samples...')\n",
    "    \n",
    "    # yes_samples_texts = clean_named_entities(pos_yes + neg_yes)\n",
    "    \n",
    "    for review in tqdm(pos_yes + neg_yes):\n",
    "    # for review in tqdm(yes_samples_texts):\n",
    "        # a, b = split_review(review)\n",
    "        a, b = split_review_random_choose_sentence(review)\n",
    "        # print(len(a), len(b))\n",
    "        prompt = f\"Paragraph A: {a}\\nParagraph B: {b}\\n\\nAre these paragraphs from the same movie review? Answer yes or no.\"\n",
    "        yes_samples.append({\n",
    "            \"contents\": [\n",
    "                {\"role\": \"user\", \"parts\": [{\"text\": prompt}]},\n",
    "                {\"role\": \"model\", \"parts\": [{\"text\": \"yes\"}]}\n",
    "            ]\n",
    "        })\n",
    "\n",
    "    pos_no_pool = [r for r in pos_reviews if r not in pos_yes] #[:50]\n",
    "    neg_no_pool = [r for r in neg_reviews if r not in neg_yes] #[:50]\n",
    "    combined_no_pool = pos_no_pool + neg_no_pool\n",
    "    random.shuffle(combined_no_pool)\n",
    "\n",
    "    print('no samples...')\n",
    "    \n",
    "    # combined_no_pool_texts = clean_named_entities(combined_no_pool)\n",
    "          \n",
    "    # paras = [split_review(r) for r in tqdm(combined_no_pool)]\n",
    "    paras = [split_review_random_choose_sentence(r) for r in tqdm(combined_no_pool)]\n",
    "    \n",
    "    # paras = [split_review(r) for r in tqdm(combined_no_pool_texts)]\n",
    "    \n",
    "    paras_a = [p[0] for p in paras]\n",
    "    paras_b = [p[1] for p in paras]\n",
    "    random.shuffle(paras_b)\n",
    "\n",
    "    no_samples = []\n",
    "    for a, b in zip(paras_a, paras_b):\n",
    "        if a.strip() != b.strip():\n",
    "            prompt = f\"Paragraph A: {a}\\nParagraph B: {b}\\n\\nAre these paragraphs from the same movie review? Answer yes or no.\"\n",
    "            no_samples.append({\n",
    "                \"contents\": [\n",
    "                    {\"role\": \"user\", \"parts\": [{\"text\": prompt}]},\n",
    "                    {\"role\": \"model\", \"parts\": [{\"text\": \"no\"}]}\n",
    "                ]\n",
    "            })\n",
    "\n",
    "    all_samples = yes_samples + no_samples\n",
    "    random.shuffle(all_samples)\n",
    "\n",
    "    split_idx = int(len(all_samples) * 0.7)\n",
    "    train_set = all_samples[:split_idx]\n",
    "    valid_set = all_samples[split_idx:]\n",
    "\n",
    "    with open(train_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for item in train_set:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    with open(valid_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for item in valid_set:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(f\"‚úÖ Train set: {len(train_set)} samples -> {train_path}\")\n",
    "    print(f\"‚úÖ Validation set: {len(valid_set)} samples -> {valid_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd919cbf-a6a0-4678-a690-0c9ca60eecf1",
   "metadata": {},
   "source": [
    "## import data with removed names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b50a818-3991-446c-a174-557f01659e40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "# JSONL Ê™îÊ°àË∑ØÂæë\n",
    "file_path = 'remove_name_comments.jsonl'\n",
    "\n",
    "data = []\n",
    "\n",
    "# ËÆÄÂèñÊØè‰∏ÄË°å JSON\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line)\n",
    "        try:\n",
    "            # ÂÆâÂÖ®ÂèñÂæó id\n",
    "            id_val = int(obj[\"id\"])\n",
    "\n",
    "            # ÂòóË©¶Âæû content.parts ÂèñÂæóÊñáÂ≠ó\n",
    "            content = obj[\"response\"][\"candidates\"][0][\"content\"]\n",
    "            if isinstance(content, dict) and \"parts\" in content:\n",
    "                text = content[\"parts\"][0][\"text\"]\n",
    "            elif isinstance(content, str):\n",
    "                text = content\n",
    "            else:\n",
    "                text = \"(ÁÑ°Ê≥ïËß£ÊûêÂÖßÂÆπ)\"\n",
    "\n",
    "            data.append({\"id\": id_val, \"text\": text})\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Ë∑≥ÈÅé‰∏ÄÁ≠ÜË≥áÊñôÔºàÂèØËÉΩÊ†ºÂºèÁï∞Â∏∏ÔºâÔºö{e}\")\n",
    "\n",
    "# Ê†πÊìö id ÊéíÂ∫è\n",
    "data_sorted = sorted(data, key=lambda x: x[\"id\"])\n",
    "\n",
    "# Ëº∏Âá∫Ê∏ÖÁêÜÂæåÁöÑ text\n",
    "# for item in data_sorted[:10]:\n",
    "#     print(item)\n",
    "#     print(\"\\n---\\n\")  # ÂèØÈÅ∏ÔºöÂä†ÂàÜÈöîÁ∑öÂçÄÂàÜÊÆµËêΩ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3067ea15-29b4-413c-a4e6-92c38dc96ade",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_X = [item[\"text\"] for item in data_sorted]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b40e92ef-f25b-4c5b-b14c-1886d639b86e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 29781.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 33191.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Train set: 1400 samples -> train_rv_name_random_sent_0701.jsonl\n",
      "‚úÖ Validation set: 600 samples -> eval_rv_name_random_sent_0701.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ÂÅáË®≠‰Ω†Â∑≤Á∂ìÊúâ X, yÔºö\n",
    "# X = [...2000ÁØáË©ïË´ñ...]\n",
    "# y = [...2000ÂÄãÊ®ôÁ±§...]\n",
    "\n",
    "# build_finetune_data(X, y, train_path=\"train_minus_1_sent.jsonl\", valid_path=\"eval_minus_1_sent.jsonl\")\n",
    "# build_finetune_data(X, y, train_path=\"train_rm_sth.jsonl\", valid_path=\"eval_rm_sth.jsonl\")\n",
    "# build_finetune_data(X, y, train_path=\"train_one_sent_and_all_pairs.jsonl\", valid_path=\"eval_one_sent_and_all_pairs.jsonl\")\n",
    "# build_sentence_pair_data(X, y, train_path=\"train_one_sent_and_all_pairs.jsonl\", valid_path=\"eval_one_sent_and_all_pairs.jsonl\")\n",
    "\n",
    "build_finetune_data(new_X, y, train_path=\"train_rv_name_random_sent_0701.jsonl\", valid_path=\"eval_rv_name_random_sent_0701.jsonl\")\n",
    "# build_finetune_data(new_X, y, train_path=\"train_rv_name_minus_first_last_sent.jsonl\", valid_path=\"eval_rv_name_minus_first_last_sent.jsonl\")\n",
    "# build_finetune_data(new_X, y, train_path=\"train_rv_name_one_sent.jsonl\", valid_path=\"eval_rv_name_one_sent.jsonl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c1caee1-3663-4885-ac99-453dcf9e22e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [03:25<00:00,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 0.8633333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "from vertexai import generative_models\n",
    "\n",
    "from google import genai\n",
    "from google.genai.types import GenerateContentConfig, ThinkingConfig\n",
    "\n",
    "\n",
    "\n",
    "model = GenerativeModel(\"gemini-2.0-flash\", \n",
    "                        safety_settings=[\n",
    "                        generative_models.SafetySetting(\n",
    "                            category=generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "                            threshold=generative_models.HarmBlockThreshold.BLOCK_NONE\n",
    "                        ),\n",
    "                        generative_models.SafetySetting(\n",
    "                            category=generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "                            threshold=generative_models.HarmBlockThreshold.BLOCK_NONE\n",
    "                        ),\n",
    "                    ]\n",
    "        )\n",
    "\n",
    "\n",
    "# Ë®≠ÂÆöÊ™îÊ°àË∑ØÂæë\n",
    "# jsonl_path = \"eval_rv_name.jsonl\"\n",
    "jsonl_path = \"eval_rv_name_random_sent.jsonl\"\n",
    "# jsonl_path = \"eval_rv_name_minus_first_last_sent.jsonl\"\n",
    "# jsonl_path = \"eval_rv_name_one_sent.jsonl\"\n",
    "\n",
    "\n",
    "# ËÆÄÂèñÂâç 10 Á≠ÜË≥áÊñô\n",
    "samples = []\n",
    "answers = []\n",
    "\n",
    "corr = 0\n",
    "eval_num = 600\n",
    "\n",
    "with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "\n",
    "        if i >= eval_num:\n",
    "            break\n",
    "        data = json.loads(line)\n",
    "        # ÂÅáË®≠‰Ω†Ë¶ÅÊ∏¨Ë©¶ÁöÑ prompt Âú® contents[0][\"parts\"][0][\"text\"]\n",
    "        prompt = data[\"contents\"][0][\"parts\"][0][\"text\"] \n",
    "        answer = data[\"contents\"][1][\"parts\"][0][\"text\"]\n",
    "        samples.append(prompt)\n",
    "        answers.append(answer)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# added 2.5 thinking budget coontrol\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)\n",
    "# added 2.5 thinking budget coontrol\n",
    "\n",
    "# Âü∑Ë°å Gemini Êé®Ë´ñ\n",
    "for idx, prompt in enumerate(tqdm(samples)):\n",
    "    # print(f\"--- Sample {idx} ---\")\n",
    "    response = model.generate_content(prompt)\n",
    "\n",
    "    try:\n",
    "        if 'no' in response.text.strip().lower() and answers[idx] == 'no':\n",
    "            corr += 1\n",
    "        elif 'yes' in response.text.strip().lower() and answers[idx] == 'yes':\n",
    "            corr += 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print('Acc', corr/len(samples))\n",
    "# print(answers, len(answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3152a13-fdb6-4b57-9765-ddba7349dee4",
   "metadata": {},
   "source": [
    "## Start Fine-tuning (based on Gemini-2.0-flash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "242605a8-e6ec-4d3d-877e-509e1d3b32e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SupervisedTuningJob\n",
      "SupervisedTuningJob created. Resource name: projects/765271398193/locations/us-central1/tuningJobs/4672263491300622336\n",
      "To use this SupervisedTuningJob in another session:\n",
      "tuning_job = sft.SupervisedTuningJob('projects/765271398193/locations/us-central1/tuningJobs/4672263491300622336')\n",
      "View Tuning Job:\n",
      "https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/4672263491300622336?project=765271398193\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-42cb2398-4881-49d2-b32a-b80485a9a217\" href=\"#view-view-vertex-resource-42cb2398-4881-49d2-b32a-b80485a9a217\">\n",
       "          <span class=\"material-icons view-vertex-icon\">tune</span>\n",
       "          <span>View Tuning Job</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-42cb2398-4881-49d2-b32a-b80485a9a217');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/4672263491300622336?project=765271398193');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/4672263491300622336?project=765271398193', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-63110fe8-239e-4950-bc51-a6837e431589\" href=\"#view-view-vertex-resource-63110fe8-239e-4950-bc51-a6837e431589\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-63110fe8-239e-4950-bc51-a6837e431589');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/tuning-experiment-20250619204412220436/runs?project=cacafly-ml-specialization');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/tuning-experiment-20250619204412220436/runs?project=cacafly-ml-specialization', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/765271398193/locations/us-central1/models/8021864212928135168@1\n",
      "projects/765271398193/locations/us-central1/endpoints/395310714069188608\n",
      "<google.cloud.aiplatform.metadata.experiment_resources.Experiment object at 0x7f2774ae41f0>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "# import vertexai\n",
    "from vertexai.tuning import sft\n",
    "\n",
    "# TODO(developer): Update and un-comment below line\n",
    "# PROJECT_ID = \"your-project-id\"\n",
    "# vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "sft_tuning_job = sft.train(\n",
    "    source_model=\"gemini-2.0-flash-001\",\n",
    "    # 1.5 and 2.0 models use the same JSONL format\n",
    "    # train_dataset=\"gs://cacafly-ml-specialization-dataset/movie_review/gemini_similarity.jsonl\",\n",
    "    # train_dataset=\"gs://cacafly-ml-specialization-dataset/movie_review/train_rm_sth.jsonl\",\n",
    "    # train_dataset=\"gs://cacafly-ml-specialization-dataset/movie_review/train_one_sent.jsonl\",\n",
    "    # train_dataset=\"gs://cacafly-ml-specialization-dataset/movie_review/train_one_sent_and_all_pairs_subset.jsonl\",\n",
    "    # train_dataset=\"gs://cacafly-ml-specialization-dataset/movie_review/train_minus_1_sent.jsonl\",\n",
    "    # train_dataset=\"gs://cacafly-ml-specialization-dataset/movie_review/train_rv_name.jsonl\",\n",
    "    train_dataset=\"gs://cacafly-ml-specialization-dataset/movie_review/train_rv_name_random_sent.jsonl\",\n",
    "    # train_dataset=\"gs://cacafly-ml-specialization-dataset/movie_review/train_rv_name_one_sent.jsonl\",\n",
    "    \n",
    "    \n",
    "    # validation_dataset=\"gs://cacafly-ml-specialization-dataset/movie_review/eval.jsonl\",\n",
    "    # machine_spec={\n",
    "    #     \"machine_type\": \"n1-standard-8\",\n",
    "    #     \"accelerator_type\": \"NVIDIA_TESLA_T4\",\n",
    "    #     \"accelerator_count\": 1\n",
    "    # }\n",
    "    epochs=5,\n",
    "    adapter_size=4,\n",
    "    learning_rate_multiplier=3.0,\n",
    "    tuned_model_display_name=\"tuned_rv_name_random_sent_gemini_2.0-flash\",\n",
    ")\n",
    "\n",
    "# Polling for job completion\n",
    "while not sft_tuning_job.has_ended:\n",
    "    time.sleep(60)\n",
    "    sft_tuning_job.refresh()\n",
    "\n",
    "print(sft_tuning_job.tuned_model_name)\n",
    "print(sft_tuning_job.tuned_model_endpoint_name)\n",
    "print(sft_tuning_job.experiment)\n",
    "\n",
    "\n",
    "# Example response:\n",
    "# projects/123456789012/locations/us-central1/models/1234567890@1\n",
    "# projects/123456789012/locations/us-central1/endpoints/123456789012345\n",
    "# <google.cloud.aiplatform.metadata.experiment_resources.Experiment object at 0x7b5b4ae07af0>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b78d6b33-096e-4b2a-86ea-892b7793b3c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0dbab38a-a89b-4a28-8b7a-294092c7b163",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment run tuning-experiment-run-20250618032415893071 skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"tuning-experiment-20250618032415893071-tuning-experiment-run-20250618032415893071-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618032415893071-tuning-experiment-run-20250618032415893071\n",
      "Context deleted. . Resource name: projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618032415893071-tuning-experiment-run-20250618032415893071\n",
      "Deleting Context resource: projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618032415893071-tuning-experiment-run-20250618032415893071\n",
      "Delete Context backing LRO: projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618032415893071-tuning-experiment-run-20250618032415893071/operations/5893042403987685376\n",
      "Context resource projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618032415893071-tuning-experiment-run-20250618032415893071 deleted.\n",
      "Deleting Context : projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618032415893071\n",
      "Context deleted. . Resource name: projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618032415893071\n",
      "Deleting Context resource: projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618032415893071\n",
      "Delete Context backing LRO: projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618032415893071/operations/4644419407299215360\n",
      "Context resource projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618032415893071 deleted.\n",
      "Experiment run tuning-experiment-run-20250618032820854186 skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"tuning-experiment-20250618032820854186-tuning-experiment-run-20250618032820854186-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618032820854186-tuning-experiment-run-20250618032820854186\n",
      "Context deleted. . Resource name: projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618032820854186-tuning-experiment-run-20250618032820854186\n",
      "Deleting Context resource: projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618032820854186-tuning-experiment-run-20250618032820854186\n",
      "Delete Context backing LRO: projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618032820854186-tuning-experiment-run-20250618032820854186/operations/8283327906214576128\n",
      "Context resource projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618032820854186-tuning-experiment-run-20250618032820854186 deleted.\n",
      "Deleting Context : projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618032820854186\n",
      "Context deleted. . Resource name: projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618032820854186\n",
      "Deleting Context resource: projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618032820854186\n",
      "Delete Context backing LRO: projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618032820854186/operations/2401626792868708352\n",
      "Context resource projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618032820854186 deleted.\n",
      "Experiment run tuning-experiment-run-20250618192158522449 skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"tuning-experiment-20250618192158522449-tuning-experiment-run-20250618192158522449-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618192158522449-tuning-experiment-run-20250618192158522449\n",
      "Context deleted. . Resource name: projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618192158522449-tuning-experiment-run-20250618192158522449\n",
      "Deleting Context resource: projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618192158522449-tuning-experiment-run-20250618192158522449\n",
      "Delete Context backing LRO: projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618192158522449-tuning-experiment-run-20250618192158522449/operations/7013312811296096256\n",
      "Context resource projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618192158522449-tuning-experiment-run-20250618192158522449 deleted.\n",
      "Deleting Context : projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618192158522449\n",
      "Context deleted. . Resource name: projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618192158522449\n",
      "Deleting Context resource: projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618192158522449\n",
      "Delete Context backing LRO: projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618192158522449/operations/1248705288261861376\n",
      "Context resource projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618192158522449 deleted.\n",
      "Experiment run tuning-experiment-run-20250618195428271072 skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"tuning-experiment-20250618195428271072-tuning-experiment-run-20250618195428271072-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618195428271072-tuning-experiment-run-20250618195428271072\n",
      "Context deleted. . Resource name: projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618195428271072-tuning-experiment-run-20250618195428271072\n",
      "Deleting Context resource: projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618195428271072-tuning-experiment-run-20250618195428271072\n",
      "Delete Context backing LRO: projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618195428271072-tuning-experiment-run-20250618195428271072/operations/5023847675905179648\n",
      "Context resource projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618195428271072-tuning-experiment-run-20250618195428271072 deleted.\n",
      "Deleting Context : projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618195428271072\n",
      "Context deleted. . Resource name: projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618195428271072\n",
      "Deleting Context resource: projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618195428271072\n",
      "Delete Context backing LRO: projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618195428271072/operations/6684550038498050048\n",
      "Context resource projects/765271398193/locations/us-central1/metadataStores/default/contexts/tuning-experiment-20250618195428271072 deleted.\n"
     ]
    }
   ],
   "source": [
    "### delete some exp\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "\n",
    "def delete_experiment_sample(\n",
    "    experiment_name: str,\n",
    "    project: str,\n",
    "    location: str,\n",
    "    delete_backing_tensorboard_runs: bool = False,\n",
    "):\n",
    "    experiment = aiplatform.Experiment(\n",
    "        experiment_name=experiment_name, project=project, location=location\n",
    "    )\n",
    "\n",
    "    experiment.delete(delete_backing_tensorboard_runs=delete_backing_tensorboard_runs)\n",
    "\n",
    "delete_experiment_sample('tuning-experiment-20250618032415893071', PROJECT_ID, LOCATION)\n",
    "delete_experiment_sample('tuning-experiment-20250618032820854186', PROJECT_ID, LOCATION)\n",
    "delete_experiment_sample('tuning-experiment-20250618192158522449', PROJECT_ID, LOCATION)\n",
    "delete_experiment_sample('tuning-experiment-20250618195428271072', PROJECT_ID, LOCATION)\n",
    "# delete_experiment_sample('tuning-experiment-20250617233525566159', PROJECT_ID, LOCATION)\n",
    "# delete_experiment_sample('tuning-experiment-20250617232307273371', PROJECT_ID, LOCATION)\n",
    "# delete_experiment_sample('tuning-experiment-20250617224904054875', PROJECT_ID, LOCATION)\n",
    "\n",
    "# 20250618030022418921\n",
    "# 20250618024234894120\n",
    "# 20250618002053445329\n",
    "# 20250617235046896136\n",
    "# 20250617233525566159\n",
    "# 20250617232307273371\n",
    "# 20250617224904054875"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b770eb26-db30-42f6-a0c4-1f24b039c805",
   "metadata": {},
   "source": [
    "## Evaluate the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6a70ce4-28be-4ae5-8553-3db4bb8fe806",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-35314c66-11c8-40e8-9799-9dffce3b9f4a\" href=\"#view-view-vertex-resource-35314c66-11c8-40e8-9799-9dffce3b9f4a\">\n",
       "          <span class=\"material-icons view-vertex-icon\">tune</span>\n",
       "          <span>View Tuning Job</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-35314c66-11c8-40e8-9799-9dffce3b9f4a');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/8472738626847899648?project=765271398193');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/8472738626847899648?project=765271398193', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [03:08<00:00,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "# import vertexai\n",
    "from vertexai.tuning import sft\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "\n",
    "# sft_tuning_job = sft.SupervisedTuningJob(\"projects/765271398193/locations/us-central1/tuningJobs/7780604853255929856\") # original split half\n",
    "# sft_tuning_job = sft.SupervisedTuningJob(\"projects/765271398193/locations/us-central1/tuningJobs/424397074411290624\") # split half and randomly choose sentences\n",
    "# sft_tuning_job = sft.SupervisedTuningJob(\"projects/765271398193/locations/us-central1/tuningJobs/4115765472111099904\") # split half and choose one sentence\n",
    "# sft_tuning_job = sft.SupervisedTuningJob(\"projects/765271398193/locations/us-central1/tuningJobs/3659916747328192512\") # split half and choose one sentence\n",
    "# sft_tuning_job = sft.SupervisedTuningJob(\"projects/765271398193/locations/us-central1/tuningJobs/7772011070373232640\") # rv name and minus first and last sentence\n",
    "# sft_tuning_job = sft.SupervisedTuningJob(\"projects/765271398193/locations/us-central1/tuningJobs/9192685646576091136\") # rv name\n",
    "sft_tuning_job = sft.SupervisedTuningJob(\"projects/765271398193/locations/us-central1/tuningJobs/8472738626847899648\") # rv name and choose 40% sentence\n",
    "# sft_tuning_job = sft.SupervisedTuningJob(\"projects/765271398193/locations/us-central1/tuningJobs/4672263491300622336\") # rv name and choose one sentence\n",
    "\n",
    "\n",
    "tuned_model = GenerativeModel(sft_tuning_job.tuned_model_endpoint_name)\n",
    "\n",
    "import json\n",
    "\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "\n",
    "# model = GenerativeModel(\"gemini-2.0-flash-001\")\n",
    "\n",
    "# Ë®≠ÂÆöÊ™îÊ°àË∑ØÂæë\n",
    "# jsonl_path = \"eval_rm_sth.jsonl\"\n",
    "# jsonl_path = \"eval_one_sent.jsonl\"\n",
    "# jsonl_path = \"eval_one_sent_and_all_pairs.jsonl\"\n",
    "# jsonl_path = \"eval_rv_name.jsonl\"\n",
    "# jsonl_path = \"eval_rv_name_minus_furst_last_sent.jsonl\"\n",
    "jsonl_path = \"eval_rv_name_random_sent_0701.jsonl\"\n",
    "# jsonl_path = \"eval_rv_name_one_sent.jsonl\"\n",
    "\n",
    "# jsonl_path = \"train.jsonl\"\n",
    "\n",
    "# ËÆÄÂèñÂâç 10 Á≠ÜË≥áÊñô\n",
    "samples = []\n",
    "answers = []\n",
    "\n",
    "corr = 0\n",
    "eval_num = 600\n",
    "\n",
    "with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= eval_num:\n",
    "            break\n",
    "        data = json.loads(line)\n",
    "        # ÂÅáË®≠‰Ω†Ë¶ÅÊ∏¨Ë©¶ÁöÑ prompt Âú® contents[0][\"parts\"][0][\"text\"]\n",
    "        prompt = data[\"contents\"][0][\"parts\"][0][\"text\"]\n",
    "        answer = data[\"contents\"][1][\"parts\"][0][\"text\"]\n",
    "        samples.append(prompt)\n",
    "        answers.append(answer)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Âü∑Ë°å Gemini Êé®Ë´ñ\n",
    "for idx, prompt in enumerate(tqdm(samples)):\n",
    "    # print(f\"--- Sample {idx} ---\")\n",
    "    response = tuned_model.generate_content(prompt)\n",
    "    # print('Response:', response.text.strip(), ', Answer:', answers[idx])\n",
    "    # if 'no' in response.text.strip().lower() and answers[idx] == 'no':\n",
    "    #     corr += 1\n",
    "    # elif 'yes' in response.text.strip().lower() and answers[idx] == 'yes':\n",
    "    #     corr += 1\n",
    "    try:\n",
    "        if 'no' in response.text.strip().lower() and answers[idx] == 'no':\n",
    "            corr += 1\n",
    "        elif 'yes' in response.text.strip().lower() and answers[idx] == 'yes':\n",
    "            corr += 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print('Acc', corr/len(samples))\n",
    "# print(answers, len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8750430b-0dc3-44f8-9a57-1b760074be4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-14.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-14:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
